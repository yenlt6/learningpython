{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated vs. Manual Testing\n",
    "Bình thường, ta hay thực hiện test mà không có kế hoạch. Bạn chỉ đang khám phá ứng dụng, phần mềm của bạn.\n",
    "\n",
    "Để có một bộ kiểm thử thủ công hoàn chỉnh, bạn cần lập danh sách tất cả các tính năng mà ứng dụng của bạn có, các loại đầu vào khác nhau mà ứng dụng có thể chấp nhận và kết quả mong đợi. Bây giờ, mỗi khi bạn thực hiện thay đổi đối với mã của mình, bạn cần phải xem qua từng mục trong danh sách đó và kiểm tra nó.\n",
    "\n",
    "Rõ ràng là không hay ho gì khi cứ lặp đi lặp lại các công việc như vậy. Đây là lúc cần kiểm thử tự động. Kiểm thử tự động là việc thực hiện kế hoạch kiểm thử của bạn (các phần của ứng dụng bạn muốn kiểm tra, thứ tự mà bạn muốn kiểm tra chúng và các phản hồi dự kiến) bằng tập lệnh thay vì con người ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Tests vs. Integration Tests\n",
    "Kiểm thử nhiều thành phần được gọi là **kiểm thử tích hợp**. Thách thức lớn với kiểm thử tích hợp là khi nó không cho kết quả mong đợi. Rất khó để chẩn đoán sự cố mà không thể xác định phần nào của hệ thống đang bị lỗi. Cho nên ta cần đến unittest. **Kiểm thử đơn vị** là bài kiểm tra nhỏ hơn, xem một thành phần duy nhất có hoạt động đúng cách hay không. Kiểm thử đơn vị giúp bạn tách biệt những gì bị hỏng trong ứng dụng của mình và khắc phục nó nhanh hơn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sum([1, 2, 3]) == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sum([1, 1, 1]) == 6, \"Should be 6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything passed\n"
     ]
    }
   ],
   "source": [
    "def test_sum():\n",
    "    assert sum([1, 2, 3]) == 6, \"Should be 6\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_sum()\n",
    "    print(\"Everything passed! Bạn vừa viết một test case đầu tiên!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Runner\n",
    "Viết test theo cách này chỉ hợp lý khi test code đơn giản, nhưng nếu nhiều hơn một testcase không đạt thì sao? Đây là nơi **test runners** xuất hiện. Test runner là một ứng dụng đặc biệt được thiết kế để chạy các test cases, kiểm tra kết quả đầu ra và cung cấp cho bạn các công cụ để gỡ lỗi và chẩn đoán các thử nghiệm và ứng dụng. Trong Python, ta có vài lựa chọn:\n",
    "* unittest\n",
    "* nose hoặc nose2 (đã từng phổ biến, nhưng đang dần bị thay thế bởi pytest)\n",
    "* pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unittest\n",
    "Hãy xem xét file main.py trong đề thi hackathon lần 1, unittest yêu cầu rằng:\n",
    "\n",
    "* Bạn đặt các tests vào các classes dưới dạng method\n",
    "* Bạn sử dụng một loạt các phương thức assert đặc biệt trong lớp unittest.TestCase thay vì câu lệnh assert được tích hợp sẵn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytest\n",
    "Hỗ trợ thực thi code unittest. pytest giúp việc viết tests đơn giản hơn với các hàm trong tệp Python bắt đầu bằng tên test_.\n",
    "\n",
    "pytest có một số tính năng tuyệt vời khác:\n",
    "\n",
    "* Hỗ trợ cho câu lệnh assert được tích hợp sẵn thay vì sử dụng các phương thức self.assert*() đặc biệt\n",
    "* Hỗ trợ lọc các test cases (python sample_skiptests.py hoặc pytest sample_skiptests.py)\n",
    "* Khả năng chạy lại từ lần kiểm thử thất bại gần nhất\n",
    "* Hệ sinh thái gồm hàng trăm plugin để mở rộng chức năng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample pytest\n",
    "File wallet.py chứa code mô phỏng hoạt động của ví điện tử và file test_wallet.py test các hoạt động của ví.\n",
    "\n",
    "Chạy tập con các test\n",
    "```\n",
    "cd testing/wallet\n",
    "\n",
    "# chạy những test case chứa từ spend trong function name\n",
    "pytest -k spend -v\n",
    "\n",
    "# chạy những test case được mark là ini (marker đã được đăng ký trong pytest.ini)\n",
    "pytest -m ini -v .\\test_wallet.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cấu trúc của một Test Case\n",
    "Cấu trúc của một testcase nên tuân theo quy trình sau:\n",
    "* Tạo đầu vào của bạn\n",
    "* Thực thi mã đang được kiểm tra, thu nhận kết quả đầu ra\n",
    "* So sánh kết quả đầu ra với kết quả mong đợi\n",
    "\n",
    "Với việc phải test hàm sum() ở trên, bạn có thể cần kiểm tra nhiều hành vi khác nhau vd như???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side Effect - Phản ứng phụ\n",
    "Khi bạn viết các test, việc xem xét giá trị trả về của một hàm thường không đơn giản như vậy. Thông thường, việc thực thi một đoạn mã sẽ thay đổi những thứ khác trong môi trường, chẳng hạn như thuộc tính của một lớp, một tệp trên hệ thống hoặc một giá trị trong cơ sở dữ liệu. Đây được gọi là tác dụng phụ và là một phần quan trọng của kiểm thử. Quyết định xem tác dụng phụ có cần được kiểm thử hay không trước khi đưa vào danh sách assertion của bạn.\n",
    "\n",
    "Nếu bạn thấy rằng đơn vị mã bạn muốn kiểm tra có nhiều tác dụng phụ, coder có thể đã vi phạm Nguyên tắc Trách nhiệm Đơn lẻ. Phá vỡ Nguyên tắc Trách nhiệm Đơn lẻ có nghĩa là đoạn mã đang làm quá nhiều thứ và tốt hơn hết là nên cấu trúc lại (refactor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixtures\n",
    "```\n",
    "pytest --fixture\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tham số hóa các hàm test với @pytest.mark.parametrize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Liệt kê các test chạy chậm nhất\n",
    "```\n",
    "pytest --durations=3\n",
    "=========================================== slowest 3 durations ============================================ \n",
    "9.76s call     tests/test_real_server.py::test_request_response\n",
    "4.32s call     test_login_user.py::test_login_no_password\n",
    "4.01s call     test_list_user.py::test_list_invaliduser\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giả lập (Mock) những đối tượng bên ngoài\n",
    "Mock là một đối tượng giả mà bạn tạo ra để trông và hoạt động giống như dữ liệu thực. Bạn hoán đổi nó với đối tượng thực tế và đánh lừa hệ thống nghĩ rằng đối tượng mock đó là đối tượng thực sự.\n",
    "\n",
    "Đầu tiên, ta dùng một dịch vụ API online - JSON Placeholder cho mục đích testing trong bài này.\n",
    "1. Dùng [reqbin](https://reqbin.com/curl)\n",
    "\n",
    "`curl -X GET 'http://jsonplaceholder.typicode.com/todos'`\n",
    "\n",
    "2. TDD - Test Driven Development\n",
    "3. Refactor code into files (services.py & constants.py)\n",
    "4. First Mock (mock_get.return_value.ok = True)\n",
    "Test đã pass, vấn đề là dịch vụ của bạn vẫn đang truy cập trực tiếp vào máy chủ bên ngoài. Khi bạn gọi get_todos(), mã của bạn đang thực hiện yêu cầu tới API endpoint và trả về kết quả phụ thuộc vào máy chủ đó đang hoạt động. Ta sẽ tách logic khỏi thư viện thực tế bằng cách hoán đổi với 1 yêu cầu giả trả về cùng một dữ liệu.\n",
    "\n",
    "5. Other ways to patch\n",
    "    1. `with patch('services.requests.get') as mock_get:`\n",
    "    2. Dùng patcher\n",
    "6. So sánh 3 cách:\n",
    "    * Sử dụng decorator khi tất cả code trong nội dung hàm test dùng chung 1 mock.\n",
    "    * Dùng context manager khi một đoạn code trong hàm test dùng 1 mock và đoạn code khác cần dùng chức năng thực.\n",
    "    * Dùng patcher khi bạn cần start và stop mocking chức năng một cách rõ ràng trong nhiều test (ví dụ: các chức năng setUp() và tearDown() trong một lớp test).\n",
    "7. Mock tất cả các hành vi của service: \n",
    "    * Ở bước 6 là mock thành công. Bây giờ cần mock cả dữ liệu\n",
    "8. Nếu ta có service khác gọi get_todos(), thì ta chỉ cần mock chính hàm get_todos() để test service mới\n",
    "9. Refactor code into Test classes.\n",
    "10. Ta đang dựa vào giả định (khá nguy hiểm) là api data trả về của service thật không thay đổi. Để xác nhận dữ liệu nhận được khớp với dữ liệu test, ta dùng context manager để so sánh cấu trúc dữ liệu (key trong json) của 2 bên. --> Contract testing\n",
    "11. Khi thực hiện tự động hóa, bạn không cần phải chạy integration_contract 100%. Dùng biến môi trường kết hợp với skipIf để bật tắt việc chạy test này.\n",
    "    `set SKIP_REAL=TRUE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test bao nhiêu là đủ??\n",
    "\n",
    "Độ phủ của mã là số dòng mã ước tính được thực thi bởi các testcase. Nếu chúng ta biết con số đó và tổng số dòng code trong chương trình, chúng ta có thể ước tính được số phần trăm mã đã thực sự được kiểm tra. Nếu ta có thêm một chỉ báo về những dòng nào chưa được test, ta có thể dễ dàng viết thêm các bài kiểm tra mới hơn để đảm bảo những dòng đó được cover.\n",
    "\n",
    "```\n",
    "!pip install coverage\n",
    "coverage run test_main.py       # sinh ra file .coverage\n",
    "coverage report -m test_main.py\n",
    "coverage html\n",
    "\n",
    "coverage report -m .\\test_main.py\n",
    "```\n",
    "\n",
    "Dùng pytest-cov để xem Test Coverage\n",
    "```\n",
    "pytest -v --cov=test_main --cov-report=html\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test API với [reqres.in](https://reqres.in/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Các tính năng khác\n",
    "* XFail\n",
    "* Tham số condition, reason, raises, run, strict\n",
    "* Chạy test song song với `pytest-xdist`\n",
    "* Tất cả trong [documentation](https://docs.pytest.org/en/latest/contents.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with Mock Server\n",
    "Tự setup mock server có HTTP Response\n",
    "\n",
    "`set/export SKIP_TAGS=real`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Những công cụ khác\n",
    "* Kiểm thử trên nhiều môi trường: Dùng tox để chạy 1 bộ test trên nhiều môi trường Python với nhiều tập dependency khác nhau.\n",
    "* CI/CD - Continuous Integration/Continuous Deployment: TravisCI, Jenkin, GithubAction....: chủ yếu dùng file yaml để điều khiển quy trình tự động hóa build và test.\n",
    "* Linter:\n",
    "    * Passive Linting With flake8: `flake8 test_todos.py`\n",
    "    * Aggressive Linting With a Code Formatter\n",
    "* Testing về hiệu năng giảm sút giữa các lần thay đổi code: pytest-benchmark\n",
    "* Lỗi Security trong app với bandit"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bd454e041cfbb879d13b54c8ad3696129392157108d388f38111cd59b6a48c26"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('python_tester_env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
